{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight engine predictive maintenance\n",
    "Video: https://vimeo.com/160024508\n",
    "\n",
    "Data source: https://c3.nasa.gov/dashlink/resources/140/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read flight data\n",
    "\n",
    "/data\n",
    "\n",
    "    /Fault_X                        -> faulty equipments (X = Fan, HPC, HPT, LPC, LPT)\n",
    "    /Nominal_X                      -> equipments without fault\n",
    "    \n",
    "        /EngineYYY                  -> engine number (3 digits)\n",
    "        \n",
    "            /FlightZZZ.csv          -> sensor data (sampled every second)\n",
    "            /EngineHealth.csv       -> engine health data (each row = 1 flight)\n",
    "            /Engine_Fuel_Effic.csv  -> engine fuel efficiency (each row = 1 flight)\n",
    "\n",
    "First, read the data folder structure as a list of tuples:\n",
    "**(path_to_folder, equipment_name (str), is_faulty (int), engine_number (int), list_of_files)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "data_path = '/nasa/data'\n",
    "\n",
    "f = [(dirpath.replace(\"\\\\\",\"/\"), \\\n",
    "      dirpath.split(\"/\")[-2].split(\"_\")[-1],                                 #equipment \\\n",
    "      True if \"Fault\" in dirpath.split(\"/\")[-2] else False,                  #is fault? \\\n",
    "      int(dirpath.split(\"/\")[-1].split(\"Engine\", 1)[1]),                     #engine num\n",
    "      sorted(filter(lambda fn: '.csv' in fn and 'Flight' in fn, filenames))  #csv files for flight data\n",
    "     )\n",
    "     for (dirpath, dirnames, filenames) in walk(data_path) \\\n",
    "     if (\"Fault_\" in dirpath or \"Nominal_\" in dirpath) \\\n",
    "     and (\"Engine\" in dirpath) \\\n",
    "     and (\"#extra\" not in dirpath) \\\n",
    "     and len(dirnames) is 0]\n",
    "\n",
    "print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read flight sensor data into Pandas.DataFrame. One dataframe per engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "def read_file(path):\n",
    "    tmp = read_csv(path)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IS_READ_DATA = False\n",
    "from pandas import concat\n",
    "from time import time\n",
    "\n",
    "st = time()\n",
    "if not IS_READ_DATA:\n",
    "    flight_data = []\n",
    "    for (path, eq_type, is_fault, eng_num, flist) in f:\n",
    "        flnum_list = []\n",
    "        ditem_list = []\n",
    "        for fname in flist:\n",
    "            full_path = \"/\".join([path, fname])\n",
    "            fl_num = int(fname.split('Flight',1)[1].split('.csv')[0])\n",
    "            flnum_list.append(fl_num)\n",
    "            ditem_list.append(read_file(full_path))\n",
    "            \n",
    "        this_df = concat(ditem_list, keys=flnum_list)\n",
    "        del this_df['time']\n",
    "        \n",
    "        #keep only one index: 'fl_num'; correct 'time' and store as regular column\n",
    "        this_df.reset_index(level=1, inplace=True)\n",
    "        this_df.rename(columns={'level_1': 'time'}, inplace=True)\n",
    "        \n",
    "        #create time window column\n",
    "        this_df['timew'] = (this_df['time'] // 10) * 10\n",
    "        \n",
    "        #append eq_type, engine_num, fault_fl_num, fault_time\n",
    "        eff = read_file('/'.join([path, 'Engine_Fuel_Effic.csv']))\n",
    "        eff['fl_num'] = xrange(1, eff.shape[0] + 1)\n",
    "        eff.set_index(['fl_num'], inplace=True)\n",
    "        \n",
    "        health = read_file('/'.join([path, 'EngineHealth.csv']))\n",
    "        health['fl_num'] = xrange(1, health.shape[0] + 1)\n",
    "        health.set_index(['fl_num'], inplace=True)\n",
    "        \n",
    "        with open('/'.join([path, 'Simulation_Info.txt']), 'r') as fl:\n",
    "            for ln in fl.readlines():\n",
    "                if 'Fault flight number:' in ln:\n",
    "                    fault_fl_num = int(ln.split('Fault flight number:',1)[1])\n",
    "                elif 'Fault time:' in ln:\n",
    "                    fault_time = int(ln.split('Fault time:',1)[1])\n",
    "        \n",
    "        flight_data.append((this_df, eq_type, eng_num, eff, (fault_fl_num, fault_time) if is_fault else None))\n",
    "    \n",
    "    IS_READ_DATA = True\n",
    "et = time()\n",
    "\n",
    "print 'Read time: ' + str(et-st) + 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature **iscruise** - True if the altitude is 35000 feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import where\n",
    "for dset in flight_data:\n",
    "    dset[0]['iscruise'] = where(dset[0]['alt']==35000, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate pairwise correlations, in each time window, between numeric columns. Correlations are symmetric, thus only correlations above the first diagonal are retained. Output dataframe is thus expected to contain 435 features (columns) and a row for each flight number and time window (**fl_num** and **timew** are indexes for this dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_corr(dset):\n",
    "    a = dset.corr().reset_index(level=2)\n",
    "    b = a.set_index(['level_2'], append=True).unstack()\n",
    "    \n",
    "    dim = a.shape[1] - 1\n",
    "    cls = [dim*i+j for i in range(0, dim) for j in range(i+1, dim)]\n",
    "    \n",
    "    all_col_names = map(lambda (x,y): x + '_' + y, b.columns.values.tolist())\n",
    "    sel_col_names = [all_col_names[i] for i in cls]\n",
    "    \n",
    "    c = b[cls]\n",
    "    c.columns = sel_col_names\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also calculate means and stdevs for each flight number and time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import concat\n",
    "\n",
    "#calculate mean and stdev in each time window for all columns; drop 'time' and 'alt' columns\n",
    "def get_ms(dset):\n",
    "    mn = dset.mean()\n",
    "    mn.drop(['time','alt'], inplace=True, axis=1)\n",
    "    mn.columns = map(lambda x: \"mean_\" + x, list(mn.columns))\n",
    "    \n",
    "    sd = dset.std()\n",
    "    sd.drop(['time','alt'], inplace=True, axis=1)\n",
    "    sd.columns = map(lambda x: \"std_\" + x, list(sd.columns))\n",
    "    \n",
    "    return concat([mn,sd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import number\n",
    "from pandas import concat\n",
    "\n",
    "st = time()\n",
    "\n",
    "dataset = []\n",
    "for fld in flight_data:\n",
    "    dset = fld[0].query('iscruise==True').select_dtypes(include=[number]).reset_index(level=0).groupby(['index','timew'])\n",
    "    dset.index.names=(['fl_num','timew'])\n",
    "    \n",
    "    #dset is now indexed by 'fl_num' and has 'time' and 'timew' as regular columns\n",
    "    d_corr = get_corr(dset)\n",
    "    d_ms = get_ms(dset)\n",
    "    \n",
    "    d_full = concat([d_corr, d_ms], axis=1)\n",
    "    d_full.index.names=(['fl_num','timew'])\n",
    "    dataset.append((fld[2], d_full))\n",
    "\n",
    "et = time()\n",
    "\n",
    "print 'Processing time: ' + str(et-st) + 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **dataset** list now contains DataFrames indexed by **fl_num** and **timew** with 491 regressors as columns (435 correlations, 28 means and 28 standard deviations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[0][1].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: compare cruise-level parameters for two flights\n",
    "All records (frequency = second) in the respective two flights are considered. <br>\n",
    "Records in the first flight are marked with target = 0, others with target = 1. <br>\n",
    "A classification model is fit. The accuracy of the fit indicates whether a difference can be inferred between the two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get prepared dataset by engine number; return only one dataset - no two engines should share the same number\n",
    "def get_dset(eng_num):\n",
    "    max_fl_num = max(map(lambda (fl_num, fl_time): fl_num, list(dataset[0][1].index.values)))\n",
    "    return filter(lambda x: x[0]==eng_num, dataset)[0][1], max_fl_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "def fit_cum_models(eng_num, forced_fl_num = None):\n",
    "    out_accuracies = []\n",
    "    dset_engine, tot_num_flights = get_dset(eng_num)\n",
    "    \n",
    "    if forced_fl_num is None:\n",
    "        fl_list = range(1, tot_num_flights+1)\n",
    "    else:\n",
    "        fl_list = [forced_fl_num]\n",
    "        \n",
    "    for fl_num in fl_list:\n",
    "        #print str(fl_num) + '...'\n",
    "        \n",
    "        #remove non-numeric fields\n",
    "        data1 = dset_engine.loc[0:fl_num].copy()\n",
    "        data1.ix[1:fl_num-1,'target'] = int(0)\n",
    "        data1.ix[fl_num:fl_num,'target'] = int(1)\n",
    "        \n",
    "        #print 'Training records with target[0]: ' + str(data1[data1['target']==0].shape[0])\n",
    "        #print 'Training records with target[1]: ' + str(data1[data1['target']==1].shape[0])\n",
    "        #print 'Total training records: ' + str(data1.shape[0])\n",
    "        \n",
    "        #prep data - select only mean_, std_ and target columns (discard cross-correlations for now)\n",
    "        ds_train = data1[filter(lambda x: 'mean_' in x or 'std_' in x or 'target' in x, data1.columns.values)] \\\n",
    "                   .fillna(method='backfill').fillna(value=1)\n",
    "        \n",
    "        target = ds_train['target']\n",
    "        del ds_train['target']\n",
    "        \n",
    "        # fit a CART model to the data\n",
    "        model = DecisionTreeClassifier(max_depth=1)\n",
    "        model.fit(ds_train, target)\n",
    "        \n",
    "        # make predictions\n",
    "        expected = target\n",
    "        predicted = model.predict(ds_train)\n",
    "        \n",
    "        #put actual & predicted values for target back in the table\n",
    "        ds_train['target'] = target\n",
    "        ds_train['predicted'] = predicted\n",
    "        \n",
    "        # summarize the fit of the model\n",
    "        acc_score = metrics.accuracy_score(expected, predicted) * 100\n",
    "        out_accuracies.append(acc_score)\n",
    "        \n",
    "        #print(metrics.classification_report(expected, predicted))\n",
    "        #print(metrics.confusion_matrix(expected, predicted))\n",
    "        #print 'Accuracy: ' + str(acc_score) + '%'\n",
    "        \n",
    "        #print out_accuracies\n",
    "        \n",
    "    return out_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit models for engine #6\n",
    "a = fit_cum_models(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build index of the relevant features (columns) in dataset, based on fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_features_idx = [i for i,j in enumerate(model.feature_importances_) if j>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data for the relevant columns in order. It seems that a difference can be made between similar states (cruise) in two different flights based on a very limited number of regressors (i.e. 1 or 2). Such insight is not really helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_train[relevant_features_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent correlation matrix visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import diag\n",
    "\n",
    "#print mod1.columns\n",
    "print 'Correlations between regressors and predicted target: '\n",
    "print ds_train.corr()['predicted']\n",
    "#mod1[['alt','predicted']].plot(subplots=True)\n",
    "\n",
    "plt.matshow(diag(ds_train.corr()['predicted']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
