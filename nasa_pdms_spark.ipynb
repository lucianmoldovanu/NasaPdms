{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight engine predictive maintenance\n",
    "Video: https://vimeo.com/160024508\n",
    "\n",
    "Data source: https://c3.nasa.gov/dashlink/resources/140/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read flight data\n",
    "\n",
    "/data\n",
    "\n",
    "    /Fault_X                        -> faulty equipments (X = Fan, HPC, HPT, LPC, LPT)\n",
    "    /Nominal_X                      -> equipments without fault\n",
    "    \n",
    "        /EngineYYY                  -> engine number (3 digits)\n",
    "        \n",
    "            /FlightZZZ.csv          -> sensor data (sampled every second)\n",
    "            /EngineHealth.csv       -> engine health data (each row = 1 flight)\n",
    "            /Engine_Fuel_Effic.csv  -> engine fuel efficiency (each row = 1 flight)\n",
    "\n",
    "First, read the data folder structure as a list of tuples:\n",
    "**(path_to_folder, equipment_name (str), is_faulty (int), engine_number (int), list_of_files)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "data_path = '/nasa/data'\n",
    "\n",
    "f = [(dirpath.replace(\"\\\\\",\"/\"), \\\n",
    "      dirpath.split(\"/\")[-2].split(\"_\")[-1],                                 #equipment \\\n",
    "      True if \"Fault\" in dirpath.split(\"/\")[-2] else False,                  #is fault? \\\n",
    "      int(dirpath.split(\"/\")[-1].split(\"Engine\", 1)[1]),                     #engine num\n",
    "      sorted(filter(lambda fn: '.csv' in fn and 'Flight' in fn, filenames))  #csv files for flight data\n",
    "     )\n",
    "     for (dirpath, dirnames, filenames) in walk(data_path) \\\n",
    "     if (\"Fault_\" in dirpath or \"Nominal_\" in dirpath) \\\n",
    "     and (\"Engine\" in dirpath) \\\n",
    "     and (\"#extra\" not in dirpath) \\\n",
    "     and len(dirnames) is 0]\n",
    "\n",
    "print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read flight sensor data into Pandas.DataFrame. One dataframe per engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "def read_file(path):\n",
    "    tmp = read_csv(path)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IS_READ_DATA = False\n",
    "from pandas import concat\n",
    "from time import time\n",
    "\n",
    "st = time()\n",
    "if not IS_READ_DATA:\n",
    "    flight_data = []\n",
    "    for (path, eq_type, is_fault, eng_num, flist) in f:\n",
    "        flnum_list = []\n",
    "        ditem_list = []\n",
    "        for fname in flist:\n",
    "            full_path = \"/\".join([path, fname])\n",
    "            fl_num = int(fname.split('Flight',1)[1].split('.csv')[0])\n",
    "            flnum_list.append(fl_num)\n",
    "            ditem_list.append(read_file(full_path))\n",
    "            \n",
    "        this_df = concat(ditem_list, keys=flnum_list)\n",
    "        del this_df['time']\n",
    "        \n",
    "        #keep only one index: 'fl_num'; correct 'time' and store as regular column\n",
    "        this_df.reset_index(level=1, inplace=True)\n",
    "        this_df.rename(columns={'level_1': 'time'}, inplace=True)\n",
    "        \n",
    "        #create time window column\n",
    "        this_df['timew'] = (this_df['time'] // 10) * 10\n",
    "        \n",
    "        #append eq_type, engine_num, fault_fl_num, fault_time\n",
    "        eff = read_file('/'.join([path, 'Engine_Fuel_Effic.csv']))\n",
    "        eff['fl_num'] = xrange(1, eff.shape[0] + 1)\n",
    "        eff.set_index(['fl_num'], inplace=True)\n",
    "        \n",
    "        health = read_file('/'.join([path, 'EngineHealth.csv']))\n",
    "        health['fl_num'] = xrange(1, health.shape[0] + 1)\n",
    "        health.set_index(['fl_num'], inplace=True)\n",
    "        \n",
    "        with open('/'.join([path, 'Simulation_Info.txt']), 'r') as fl:\n",
    "            for ln in fl.readlines():\n",
    "                if 'Fault flight number:' in ln:\n",
    "                    fault_fl_num = int(ln.split('Fault flight number:',1)[1])\n",
    "                elif 'Fault time:' in ln:\n",
    "                    fault_time = int(ln.split('Fault time:',1)[1])\n",
    "        \n",
    "        flight_data.append((this_df, eq_type, eng_num, eff, (fault_fl_num, fault_time) if is_fault else None))\n",
    "    \n",
    "    IS_READ_DATA = True\n",
    "et = time()\n",
    "\n",
    "print 'Read time: ' + str(et-st) + 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature **iscruise** - True if the altitude is 35000 feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import where\n",
    "for dset in flight_data:\n",
    "    dset[0]['iscruise'] = where(dset[0]['alt']==35000, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate pairwise correlations, in each time window, between numeric columns. Correlations are symmetric, thus only correlations above the first diagonal are retained. Output dataframe is thus expected to contain 435 features (columns) and a row for each flight number and time window (**fl_num** and **timew** are indexes for this dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_corr(dset):\n",
    "    a = dset.corr().reset_index(level=2)\n",
    "    b = a.set_index(['level_2'], append=True).unstack()\n",
    "    \n",
    "    dim = a.shape[1] - 1\n",
    "    cls = [dim*i+j for i in range(0, dim) for j in range(i+1, dim)]\n",
    "    \n",
    "    all_col_names = map(lambda (x,y): x + '_' + y, b.columns.values.tolist())\n",
    "    sel_col_names = [all_col_names[i] for i in cls]\n",
    "    \n",
    "    c = b[cls]\n",
    "    c.columns = sel_col_names\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also calculate means and stdevs for each flight number and time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import concat\n",
    "\n",
    "#calculate mean and stdev in each time window for all columns; drop 'time' and 'alt' columns\n",
    "def get_ms(dset):\n",
    "    mn = dset.mean()\n",
    "    mn.drop(['time','alt'], inplace=True, axis=1)\n",
    "    mn.columns = map(lambda x: \"mean_\" + x, list(mn.columns))\n",
    "    \n",
    "    sd = dset.std()\n",
    "    sd.drop(['time','alt'], inplace=True, axis=1)\n",
    "    sd.columns = map(lambda x: \"std_\" + x, list(sd.columns))\n",
    "    \n",
    "    return concat([mn,sd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import number\n",
    "from pandas import concat\n",
    "\n",
    "st = time()\n",
    "\n",
    "corrs = []\n",
    "for fld in flight_data:\n",
    "    dset = fld[0].query('iscruise==True').select_dtypes(include=[number]).reset_index(level=0).groupby(['index','timew'])\n",
    "    dset.index.names=(['fl_num','timew'])\n",
    "    \n",
    "    #dset is now indexed by 'fl_num' and has 'time' and 'timew' as regular columns\n",
    "    d_corr = get_corr(dset)\n",
    "    d_ms = get_ms(dset)\n",
    "    \n",
    "    d_full = concat([d_corr, d_ms], axis=1)\n",
    "    corrs.append(d_full)\n",
    "\n",
    "et = time()\n",
    "\n",
    "print 'Processing time: ' + str(et-st) + 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **corrs** list now contains DataFrames indexed by **fl_num** and **timew** with 491 regressors as columns (435 correlations, 28 means and 28 standard deviations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrs[0].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: compare cruise-level parameters for two flights\n",
    "All records (frequency = second) in the respective two flights are considered. <br>\n",
    "Records in the first flight are marked with target = 0, others with target = 1. <br>\n",
    "A classification model is fit. The accuracy of the fit indicates whether a difference can be inferred between the two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLIGHT_1 = 1\n",
    "FLIGHT_2 = 5\n",
    "\n",
    "#remove non-numeric fields\n",
    "mod1 = equip_df.query('fl_num==' + str(FLIGHT_1) + ' or fl_num==' + str(FLIGHT_2))\n",
    "\n",
    "mod1.ix[FLIGHT_1:FLIGHT_1,'target'] = 0\n",
    "mod1.ix[FLIGHT_2:FLIGHT_2,'target'] = 1\n",
    "target = mod1['target']\n",
    "\n",
    "mod1 = mod1.drop(['time','eq','engine_num','isfault','iscruise','target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Training records with target=0: ' + str(mod1[mod1['target']==0].shape[0])\n",
    "print 'Training records with target=1: ' + str(mod1[mod1['target']==1].shape[0])\n",
    "print 'Total training records: ' + str(mod1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(mod1, target)\n",
    "\n",
    "# make predictions\n",
    "expected = target\n",
    "predicted = model.predict(mod1)\n",
    "\n",
    "#put target & predicted values back to \n",
    "mod1['target'] = target\n",
    "mod1['predicted'] = predicted\n",
    "\n",
    "# summarize the fit of the model\n",
    "#print(metrics.classification_report(expected, predicted))\n",
    "#print(metrics.confusion_matrix(expected, predicted))\n",
    "print 'Accuracy: ' + str(metrics.accuracy_score(expected, predicted) * 100) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy of fit is high, no explanatory variables seems to correlate well with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import diag\n",
    "\n",
    "#print mod1.columns\n",
    "print mod1.corr()['predicted']\n",
    "#mod1[['alt','predicted']].plot(subplots=True)\n",
    "\n",
    "plt.matshow(diag(mod1.corr()['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wSpec = Window.orderBy(\"time\")\n",
    "#a.select('time', fsql.lag('time', 1).over(wSpec).alias('time_lagged')).take(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
